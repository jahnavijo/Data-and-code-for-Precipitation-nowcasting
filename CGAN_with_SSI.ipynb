{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CGAN_with_SSI.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Xn8955kBPI1q",
        "PNJ7u0LGSpzz",
        "JYncRmOHl3Yz",
        "ueFSCpob5iPp"
      ],
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JnZCq1hc2reG"
      },
      "source": [
        "US Cordinates are : (West, South, East, North)\n",
        "\n",
        "-124,29,-70,49\n",
        "\n",
        "North East cordinates are: -82.9, 33.1, -76.5,39.5"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "metadata": {
        "id": "RrUBb7WNsrU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9kYJxaDorf0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/gdrive/My Drive/Colab Notebooks/PrecipitationNowcasting\")\n",
        "os.getcwd()\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xarray as xr \n",
        "import torch\n",
        "import keras\n",
        "# from keras.optimizers import Adam\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.models import Model\n",
        "from keras.models import Input\n",
        "from keras.layers import *\n",
        "from tensorflow.keras.callbacks import EarlyStopping ,ReduceLROnPlateau ,ModelCheckpoint ,TensorBoard\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from numpy import load\n",
        "from numpy import zeros\n",
        "from numpy import ones\n",
        "from numpy.random import randint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from matplotlib import pyplot\n",
        "from keras.models import load_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xr_Jan20 = xr.open_mfdataset('data-virginia/Jan20/*.nc4')\n",
        "xr_Feb20 = xr.open_mfdataset('data-virginia/Feb20/*.nc4')\n",
        "xr_Mar20 = xr.open_mfdataset('data-virginia/Mar20/*.nc4')\n",
        "xr_Apr20 = xr.open_mfdataset('data-virginia/Apr20/*.nc4')\n",
        "xr_May20 = xr.open_mfdataset('data-virginia/May20/*.nc4')\n",
        "xr_Jun20 = xr.open_mfdataset('data-virginia/Jun20/*.nc4')\n",
        "xr_Jul20 = xr.open_mfdataset('data-virginia/Jul20/*.nc4')\n",
        "xr_Aug20 = xr.open_mfdataset('data-virginia/Aug20/*.nc4')\n",
        "xr_Sep20 = xr.open_mfdataset('data-virginia/Sep20/*.nc4')\n",
        "xr_Oct20 = xr.open_mfdataset('data-virginia/Oct20/*.nc4')\n",
        "xr_Nov20 = xr.open_mfdataset('data-virginia/Nov20/*.nc4')\n",
        "xr_Dec20 = xr.open_mfdataset('data-virginia/Dec20/*.nc4')"
      ],
      "metadata": {
        "id": "cs4rnYXDBO22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xr_all = xr.merge([xr_Jan20,xr_Feb20,xr_Mar20,xr_Apr20,xr_May20,xr_Jun20,xr_Jul20,xr_Aug20,xr_Sep20,xr_Oct20,xr_Nov20,xr_Dec20])\n",
        "xr_all.to_netcdf('IMERG_finalrun_VA_NC_SC_2020.nc4')"
      ],
      "metadata": {
        "id": "PtLuxZxPBTYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xr_1 = xr.open_dataset('IMERG_finalrun_VA_NC_SC_2020.nc4')"
      ],
      "metadata": {
        "id": "o04NqgVOtM_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = xr_1.to_dataframe().reset_index().round(2)"
      ],
      "metadata": {
        "id": "CVIB1rLopZTz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "df[\"time\"]= pd.to_datetime(df.time)\n",
        "df = df.sort_values(by=[\"time\",\"lat\",\"lon\"]).reset_index(drop=True)\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "QmWXSiM8pkrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(df[\"time\"].nunique())\n"
      ],
      "metadata": {
        "id": "4YTkH2HVjOlZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CGAN model and evaluation metrics"
      ],
      "metadata": {
        "id": "Xn8955kBPI1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CGAN model taken from machine learning mastery\n",
        "\n",
        "# https://machinelearningmastery.com/how-to-develop-a-pix2pix-gan-for-image-to-image-translation/\n",
        "\n",
        "# define the discriminator model\n",
        "def define_discriminator(input_shape=(64, 64, 4), target_shape =(64, 64, 1)):\n",
        "\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# source image input\n",
        "\tin_src_image = Input(shape=input_shape)\n",
        "\t# target image input\n",
        "\tin_target_image = Input(shape=target_shape)\n",
        "\t# concatenate images channel-wise\n",
        "\tmerged = Concatenate()([in_src_image, in_target_image])\n",
        "\t# C64\n",
        "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C128\n",
        "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C256\n",
        "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# C512\n",
        "\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# second last output layer\n",
        "\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "\td = BatchNormalization()(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\t# patch output\n",
        "\td = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "\tpatch_out = Activation('sigmoid')(d)\n",
        "\t# define model\n",
        "\tmodel = Model([in_src_image, in_target_image], patch_out)\n",
        "\t# compile model\n",
        "\topt = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "G_G8zm0Hmf0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# discriminator = define_discriminator()\n",
        "# discriminator.summary()"
      ],
      "metadata": {
        "id": "fi6Xwcsi0TA-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define an encoder block\n",
        "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# add downsampling layer\n",
        "\tg = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
        "\t# conditionally add batch normalization\n",
        "\tif batchnorm:\n",
        "\t\tg = BatchNormalization()(g, training=True)\n",
        "\t# leaky relu activation\n",
        "\tg = LeakyReLU(alpha=0.2)(g)\n",
        "\treturn g\n",
        " \n",
        "# define a decoder block\n",
        "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# add upsampling layer\n",
        "\tg = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
        "\t# add batch normalization\n",
        "\tg = BatchNormalization()(g, training=True)\n",
        "\t# conditionally add dropout\n",
        "\tif dropout:\n",
        "\t\tg = Dropout(0.5)(g, training=True)\n",
        "\t# merge with skip connection\n",
        "\tg = Concatenate()([g, skip_in])\n",
        "\t# relu activation\n",
        "\tg = Activation('relu')(g)\n",
        "\treturn g\n",
        " \n",
        " # define the standalone generator model\n",
        "def define_generator(image_shape=(64,64,3)):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# image input\n",
        "\tin_image = Input(shape=image_shape)\n",
        "\t# encoder model\n",
        "\te1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
        "\te2 = define_encoder_block(e1, 128)\n",
        "\te3 = define_encoder_block(e2, 256)\n",
        "\te4 = define_encoder_block(e3, 512)\n",
        "\te5 = define_encoder_block(e4, 512)\n",
        "\t# bottleneck, no batch norm and relu\n",
        "\tb = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e5)\n",
        "\tb = Activation('relu')(b)\n",
        "\t# decoder model\n",
        "\td3 = decoder_block(b, e5, 512)\n",
        "\td4 = decoder_block(d3, e4, 512, dropout=False)\n",
        "\td5 = decoder_block(d4, e3, 256, dropout=False)\n",
        "\td6 = decoder_block(d5, e2, 128, dropout=False)\n",
        "\td7 = decoder_block(d6, e1, 64, dropout=False)\n",
        "\t# output\n",
        "\tg = Conv2DTranspose(1, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n",
        "\tout_image = Activation('tanh')(g)\n",
        "\t# define model\n",
        "\tmodel = Model(in_image, out_image)\n",
        "\treturn model\n"
      ],
      "metadata": {
        "id": "0xxrQQcrmiZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = define_generator(image_shape=(64, 64, 4))\n",
        "generator.summary()"
      ],
      "metadata": {
        "id": "O2a4y7QcmicF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SSIMLoss(y_true, y_pred):\n",
        "  SSI_loss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, 1.0, filter_size = 3))\n",
        "  mae_loss = tf.reduce_mean(tf.abs(y_true - y_pred))\n",
        "  mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "  total_loss = SSI_loss + mae_loss\n",
        "  return total_loss"
      ],
      "metadata": {
        "id": "ipkMaAcyBZ2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the combined generator and discriminator model, for updating the generator\n",
        "def define_gan(g_model, d_model, image_shape):\n",
        "\t# make weights in the discriminator not trainable\n",
        "\tfor layer in d_model.layers:\n",
        "\t\tif not isinstance(layer, BatchNormalization):\n",
        "\t\t\tlayer.trainable = False\n",
        "\t# define the source image\n",
        "\tin_src = Input(shape=image_shape)\n",
        "\t# connect the source image to the generator input\n",
        "\tgen_out = g_model(in_src)\n",
        "\t# connect the source input and generator output to the discriminator input\n",
        "\tdis_out = d_model([in_src, gen_out])\n",
        "\t# src image as input, generated image and classification output\n",
        "\tmodel = Model(in_src, [dis_out, gen_out])\n",
        "\t# compile model\n",
        "\topt = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss=['binary_crossentropy',  'mse'], optimizer=opt, loss_weights=[1, 100])\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "3P4QGN7Kmiew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select a batch of random samples, returns images and target\n",
        "def generate_real_samples(data, target, n_samples, patch_shape):\n",
        "\t# unpack dataset\n",
        "\ttrainA, trainB = data, target\n",
        "\t# choose random instances\n",
        "\tix = randint(0, trainA.shape[0], n_samples)\n",
        "\t# retrieve selected images\n",
        "\tX1, X2 = trainA[ix], trainB[ix]\n",
        "\t# generate 'real' class labels (1)\n",
        "\ty = ones((n_samples, patch_shape, patch_shape, 1))\n",
        "\treturn [X1, X2], y"
      ],
      "metadata": {
        "id": "K1XOZydomiiF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate a batch of images, returns images and targets\n",
        "def generate_fake_samples(g_model, samples, patch_shape):\n",
        "\t# generate fake instance\n",
        "\tX = g_model.predict(samples)\n",
        "\t# create 'fake' class labels (0)\n",
        "\ty = zeros((len(X), patch_shape, patch_shape, 1))\n",
        "\treturn X, y"
      ],
      "metadata": {
        "id": "usqeBGiDmwM9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate samples and save as a plot and save the model\n",
        "def summarize_performance(step, g_model, data, target, leadtime, plot_path, model_path, n_samples=3):\n",
        "  # select a sample of input images\n",
        "  [X_realA, X_realB], _ = generate_real_samples(data, target, n_samples, 1)\n",
        "  # generate a batch of fake samples\n",
        "  X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n",
        "  # scale all pixels from [-1,1] to [0,1]\n",
        "  X_realA = (X_realA + 1) / 2.0\n",
        "  X_realB = (X_realB + 1) / 2.0\n",
        "  X_fakeB = (X_fakeB + 1) / 2.0\n",
        "  # plot real source images\n",
        "  pyplot.figure(figsize = (8, 8))\n",
        "  for i in range(n_samples):\n",
        "    pyplot.subplot(3, n_samples, 1 + i)\n",
        "    pyplot.title('Real input images')\n",
        "    pyplot.axis('off')\n",
        "    pyplot.imshow(X_realA[i][:,:,-1])\n",
        "  # plot generated target image\n",
        "  for i in range(n_samples): \n",
        "    pyplot.subplot(3, n_samples, 1 + n_samples + i)\n",
        "    pyplot.title('Generated target images')\n",
        "    pyplot.axis('off')\n",
        "    pyplot.imshow(X_fakeB[i][:,:,-1])\n",
        "  # plot real target image\n",
        "  for i in range(n_samples):\n",
        "    pyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\n",
        "    pyplot.title('Real target images') \n",
        "    pyplot.axis('off')\n",
        "    pyplot.imshow(X_realB[i][:,:,-1])\n",
        "  # save plot to file\n",
        "  filename1 = '%s/plot_%06d_%s.png' % (plot_path, step+1, leadtime)\n",
        "  pyplot.savefig(filename1)\n",
        "  pyplot.close()\n",
        "  # save the generator model\n",
        "  filename2 = '%s/model_%06d.h5' % (model_path, step+1)\n",
        "  g_model.save(filename2)\n",
        "  print('>Saved: %s and %s' % (filename1, filename2))"
      ],
      "metadata": {
        "id": "uduxnI6ymxGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train pix2pix model\n",
        "def train_model(d_model, g_model, gan_model, data, target, n_epochs, n_batch,leadtime, plot_path, model_path):\n",
        "  # print(\"hi\")\n",
        "  # determine the output square shape of the discriminator\n",
        "  n_patch = d_model.output_shape[1]\n",
        "  # print(\"hi again\")\n",
        "  # unpack dataset\n",
        "  trainA, trainB = data, target\n",
        "  # calculate the number of batches per training epoch\n",
        "  bat_per_epo = int(len(trainA) / n_batch)\n",
        "  # calculate the number of training iterations\n",
        "  n_steps = bat_per_epo * n_epochs\n",
        "  print(n_steps)\n",
        "  # manually enumerate epochs\n",
        "  for i in range(n_steps):\n",
        "    # select a batch of real samples\n",
        "    [X_realA, X_realB], y_real = generate_real_samples(data, target, n_batch, n_patch)\n",
        "    # generate a batch of fake samples\n",
        "    X_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
        "    # update discriminator for real samples\n",
        "    d_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
        "    # update discriminator for generated samples\n",
        "    d_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
        "    # update the generator\n",
        "    g_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
        "    # summarize performance\n",
        "    print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, d_loss1, d_loss2, g_loss))\n",
        "    # summarize model performance\n",
        "    if (i+1) % (bat_per_epo * 10) == 0:\n",
        "      summarize_performance(i, g_model, data, target,leadtime, plot_path, model_path)\n"
      ],
      "metadata": {
        "id": "CQ4YwHvpm0OM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prep_clf(obs, sim, threshold=0.5):\n",
        "\n",
        "    obs = np.where(obs >= threshold, 1, 0)\n",
        "    sim = np.where(sim >= threshold, 1, 0)\n",
        "\n",
        "    # True positive (TP)\n",
        "    hits = np.sum((obs == 1) & (sim == 1))\n",
        "\n",
        "    # False negative (FN)\n",
        "    misses = np.sum((obs == 1) & (sim == 0))\n",
        "\n",
        "    # False positive (FP)\n",
        "    falsealarms = np.sum((obs == 0) & (sim == 1))\n",
        "\n",
        "    # True negative (TN)\n",
        "    correctnegatives = np.sum((obs == 0) & (sim == 0))\n",
        "\n",
        "    return hits, misses, falsealarms, correctnegatives\n",
        "\n",
        "def CSI(obs, sim, threshold=0.5):\n",
        "\n",
        "    hits, misses, falsealarms, correctnegatives = prep_clf(obs=obs, sim=sim,\n",
        "                                                           threshold=threshold)\n",
        "\n",
        "    return hits / (hits + misses + falsealarms)\n",
        "\n",
        "def FAR(obs, sim, threshold=0.5):\n",
        "  \n",
        "    hits, misses, falsealarms, correctnegatives = prep_clf(obs=obs, sim=sim,\n",
        "                                                           threshold=threshold)\n",
        "\n",
        "    return falsealarms / (hits + falsealarms)\n",
        "\n",
        "\n",
        "def POD(obs, sim, threshold=0.5):\n",
        "    \n",
        "    hits, misses, falsealarms, correctnegatives = prep_clf(obs=obs, sim=sim,\n",
        "                                                           threshold=threshold)\n",
        "\n",
        "    return hits / (hits + misses)\n",
        "\n",
        "\n",
        "def HSS(obs, sim, threshold=0.5):\n",
        "    \n",
        "    hits, misses, falsealarms, correctnegatives = prep_clf(obs=obs, sim=sim,\n",
        "                                                           threshold=threshold)\n",
        "\n",
        "    HSS_num = 2 * (hits * correctnegatives - misses * falsealarms)\n",
        "    HSS_den = (misses**2 + falsealarms**2 + 2*hits*correctnegatives +\n",
        "               (misses + falsealarms)*(hits + correctnegatives))\n",
        "\n",
        "    return HSS_num / HSS_den\n"
      ],
      "metadata": {
        "id": "8hKra4LVr4LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NyY09Apjr8HA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helper functions to derive dataset-A and dataset-B"
      ],
      "metadata": {
        "id": "PNJ7u0LGSpzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to retrieve images with atleast minimum number of rainy pixels (Additional parameter threshold is to selected the minimum rainfall rate)\n",
        "def get_sequences_gt_threshold(threshold, train, percentage_of_rain_pixels):\n",
        "  selected_images = dict()\n",
        "  indx = []\n",
        "  pixels = train.shape[1]\n",
        "  for i in range(0, len(train)): \n",
        "    img = train[i]\n",
        "    pixels_gt = img[img > threshold]\n",
        "    if len(pixels_gt) >= int(percentage_of_rain_pixels * pixels):\n",
        "      selected_images[i] = img\n",
        "      indx.append(i)\n",
        "  # Breakes sequence into multiple sequences whenever there is gap in the index (idx)\n",
        "  # and saves those sequences to list\n",
        "  seq_50 = []\n",
        "  all_50 =[]\n",
        "  for i in range(0, len(indx)-1):\n",
        "    if indx[i+1] - indx[i] == 1:\n",
        "      seq_50.append(indx[i])\n",
        "    else:\n",
        "      seq_50.append(indx[i])\n",
        "      if len(seq_50) >= 3:      # sequence should be continuous with atleast three values\n",
        "        all_50.append(seq_50)\n",
        "      seq_50 = []\n",
        "  # print(all_50)\n",
        "  \n",
        "  # Compares above generated sequences with key of dictionary (which has index and values as key-value pairs) \n",
        "  # and generates dataset for later use (for temporal windows)\n",
        "  \n",
        "  sub = []\n",
        "  full_50 = []\n",
        "  for i in all_50:\n",
        "    for j in i:\n",
        "      for k, v in selected_images.items():\n",
        "        if j==k:\n",
        "          sub.append(v)\n",
        "    full_50.append(sub)\n",
        "    sub = []\n",
        "  return full_50\n",
        "\n"
      ],
      "metadata": {
        "id": "u-QpWobitivy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def windowed_data(dataset, input_length, output_length):\n",
        "  data = []\n",
        "  labels = []\n",
        "  for i in range(len(dataset)):\n",
        "    single = dataset[i]\n",
        "    for j in range(len(single) - input_length-output_length + 1):\n",
        "      ind = single[j: j+input_length]\n",
        "      data.append(ind)\n",
        "      label = single[j+input_length+output_length-1]\n",
        "      labels.append(label)\n",
        "  return np.array(data), np.array(labels)\n"
      ],
      "metadata": {
        "id": "J1kGnK8PKw7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "azaYoASITbfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling on dataset-A using CGAN"
      ],
      "metadata": {
        "id": "JYncRmOHl3Yz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# full data\n",
        "# Full data\n",
        "X_full = df[[\"precipitationCal\"]]\n",
        "\n",
        "newdata = X_full.values\n",
        "print(len(newdata))\n",
        "\n",
        "full = np.array_split(newdata, 17548)\n",
        "full = np.array(full)\n",
        "print(full.shape)\n",
        "\n",
        "full_50 = get_sequences_gt_threshold(0, full, 0.5) \n",
        "print(len(full_50))\n",
        "\n",
        "print(\"=============== Full dataset ===================\")\n",
        "\n",
        "\n",
        "x_full_50, y_full_50 = windowed_data(full_50, 4, 8)\n",
        "\n",
        "print(x_full_50.shape)\n",
        "print(y_full_50.shape)\n",
        "\n",
        "x_full_50 = x_full_50.transpose(0, 2, 1, 3)\n",
        "print(x_full_50.shape)\n",
        "\n",
        "X_full_50 = x_full_50.reshape(x_full_50.shape[0], 64, 64, x_full_50.shape[2] * x_full_50.shape[3])\n",
        "Y_full_50 = y_full_50.reshape(y_full_50.shape[0], 64, 64, y_full_50.shape[2])\n",
        "print(X_full_50.shape)\n",
        "print(Y_full_50.shape)\n",
        "\n",
        "print(X_full_50.max())\n",
        "print(Y_full_50.max())\n",
        "\n",
        "\n",
        "print(X_full_50.min())\n",
        "print(Y_full_50.min())\n",
        "\n",
        "\n",
        "full_50 = X_full_50.max()\n",
        "X_full_50 = (X_full_50 - 0.5 * full_50) / (0.5 * full_50)\n",
        "Y_full_50 = (Y_full_50 - 0.5 * full_50) / (0.5 * full_50)\n",
        "\n",
        "print(X_full_50.max())\n",
        "print(Y_full_50.max())\n",
        "\n",
        "\n",
        "print(X_full_50.min())\n",
        "print(Y_full_50.min())"
      ],
      "metadata": {
        "id": "wFw3uck1RKOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "# prepare cross validation\n",
        "kfold = KFold(5)\n",
        "i = 1\n",
        "accuracy = []\n",
        "CSI_all = []\n",
        "POD_all = []\n",
        "FAR_all = []\n",
        "HSS_all = []\n",
        "\n",
        "# enumerate splits\n",
        "for train, test in kfold.split(X_full_50, Y_full_50):\n",
        "  print(i) \n",
        "  print(X_full_50[train].shape, Y_full_50[train].shape, X_full_50[test].shape, Y_full_50[test].shape)\n",
        "  data, target = X_full_50[train], Y_full_50[train]\n",
        "  print('Loaded', data.shape, target.shape)\n",
        "  input_shape = data.shape[1:]\n",
        "  target_shape = target.shape[1:]\n",
        "  # define the models\n",
        "  d_model = define_discriminator(input_shape, target_shape)\n",
        "  g_model = define_generator(input_shape)\n",
        "  # define the composite model\n",
        "  gan_model = define_gan(g_model, d_model, input_shape)\n",
        "  # train model\n",
        "  model = train_model(d_model, g_model, gan_model, data, target, 1, 16,'2hr', 'Plots_50','Models_50')\n",
        "  # save the generator model\n",
        "  filename2 = 'Model_50/model_%02d.h5' % i\n",
        "  g_model.save(filename2)\n",
        "  model = load_model(filename2)\n",
        "  gen_images_20 = model.predict(X_full_50[test])\n",
        "  SSI = tf.reduce_mean(tf.image.ssim(Y_full_50[test], gen_images_20, 1.0, filter_size = 3))\n",
        "  accuracy.append(SSI)\n",
        "  Y_pred_20 = (gen_images_20 * 0.5 * full_50) + (0.5 * full_50)\n",
        "  Y_full_50[test]  = (Y_full_50[test] * 0.5 * full_50) + (0.5 * full_50)\n",
        "  CSI_index = CSI(Y_full_50[test].squeeze(), Y_pred_20.squeeze() , threshold = 0.5)\n",
        "  POD_index = POD(Y_full_50[test].squeeze(), Y_pred_20.squeeze() , threshold = 0.5)\n",
        "  FAR_index = FAR(Y_full_50[test].squeeze(), Y_pred_20.squeeze() , threshold = 0.5)\n",
        "  HSS_index = HSS(Y_full_50[test].squeeze(), Y_pred_20.squeeze() , threshold = 0.5)\n",
        "  CSI_all.append(CSI_index)\n",
        "  POD_all.append(POD_index)\n",
        "  FAR_all.append(FAR_index)\n",
        "  HSS_all.append(HSS_index)\n",
        "  Y_full_50[test] = (Y_full_50[test] - 0.5 * full_50) / (0.5 * full_50)\n",
        "  i = i + 1\n",
        "  "
      ],
      "metadata": {
        "id": "BNK-1AzeRAO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SSI_mean = tf.math.reduce_mean(accuracy)\n",
        "print(SSI_mean)\n",
        "# print(tf.math.reduce_mean(accuracy))\n",
        "print(average(CSI_all))\n",
        "print(average(POD_all))\n",
        "print(average(FAR_all))\n",
        "print(average(HSS_all))"
      ],
      "metadata": {
        "id": "WyTr0_QiTNCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling on dataset-B using CGAN"
      ],
      "metadata": {
        "id": "ueFSCpob5iPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# full data\n",
        "# Full data\n",
        "X_full = df[[\"precipitationCal\"]]\n",
        "\n",
        "newdata = X_full.values\n",
        "print(len(newdata))\n",
        "\n",
        "full = np.array_split(newdata, 17548)\n",
        "full = np.array(full)\n",
        "print(full.shape)\n",
        "\n",
        "full_20 = get_sequences_gt_threshold(0, full, 0.2) \n",
        "print(len(full_20))\n",
        "\n",
        "print(\"=============== Full dataset ===================\")\n",
        "\n",
        "\n",
        "x_full_20, y_full_20 = windowed_data(full_20, 4, 4)\n",
        "\n",
        "print(x_full_20.shape)\n",
        "print(y_full_20.shape)\n",
        "\n",
        "x_full_20 = x_full_20.transpose(0, 2, 1, 3)\n",
        "print(x_full_20.shape)\n",
        "\n",
        "X_full_20 = x_full_20.reshape(x_full_20.shape[0], 64, 64, x_full_20.shape[2] * x_full_20.shape[3])\n",
        "Y_full_20 = y_full_20.reshape(y_full_20.shape[0], 64, 64, y_full_20.shape[2])\n",
        "print(X_full_20.shape)\n",
        "print(Y_full_20.shape)\n",
        "\n",
        "print(X_full_20.max())\n",
        "print(Y_full_20.max())\n",
        "\n",
        "\n",
        "print(X_full_20.min())\n",
        "print(Y_full_20.min())\n",
        "\n",
        "\n",
        "full_20 = Y_full_20.max()\n",
        "X_full_20 = (X_full_20 - 0.5 * full_20) / (0.5 * full_20)\n",
        "Y_full_20 = (Y_full_20 - 0.5 * full_20) / (0.5 * full_20)\n",
        "\n",
        "print(X_full_20.max())\n",
        "print(Y_full_20.max())\n",
        "\n",
        "\n",
        "print(X_full_20.min())\n",
        "print(Y_full_20.min())"
      ],
      "metadata": {
        "id": "qiOua27yrtsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "# prepare cross validation\n",
        "kfold = KFold(5)\n",
        "i = 1\n",
        "accuracy = []\n",
        "CSI_all = []\n",
        "POD_all = []\n",
        "FAR_all = []\n",
        "HSS_all = []\n",
        "\n",
        "# enumerate splits\n",
        "for train, test in kfold.split(X_full_20, Y_full_20):\n",
        "  print(i) \n",
        "  print(X_full_20[train].shape, Y_full_20[train].shape, X_full_20[test].shape, Y_full_20[test].shape)\n",
        "  data, target = X_full_20[train], Y_full_20[train]\n",
        "  print('Loaded', data.shape, target.shape)\n",
        "  input_shape = data.shape[1:]\n",
        "  target_shape = target.shape[1:]\n",
        "  # define the models\n",
        "  d_model = define_discriminator(input_shape, target_shape)\n",
        "  g_model = define_generator(input_shape)\n",
        "  # define the composite model\n",
        "  gan_model = define_gan(g_model, d_model, input_shape)\n",
        "  # train model\n",
        "  model = train_model(d_model, g_model, gan_model, data, target, 1, 64,'30mins', 'Plots_20','Models_20')\n",
        "  # save the generator model\n",
        "  filename2 = 'Model_20/model_%02d.h5' % i\n",
        "  g_model.save(filename2)\n",
        "  model = load_model(filename2)\n",
        "  gen_images_20 = model.predict(X_full_20[test])\n",
        "  SSI = tf.reduce_mean(tf.image.ssim(Y_full_20[test], gen_images_20, 1.0, filter_size = 3))\n",
        "  accuracy.append(SSI)\n",
        "  Y_pred_20 = (gen_images_20 * 0.5 * full_20) + (0.5 * full_20)\n",
        "  Y_full_20[test]  = (Y_full_20[test] * 0.5 * full_20) + (0.5 * full_20)\n",
        "  CSI_index = CSI(Y_full_20[test].squeeze(), Y_pred_20.squeeze() , threshold = 0.5)\n",
        "  POD_index = POD(Y_full_20[test].squeeze(), Y_pred_20.squeeze() , threshold = 0.5)\n",
        "  FAR_index = FAR(Y_full_20[test].squeeze(), Y_pred_20.squeeze() , threshold = 0.5)\n",
        "  HSS_index = HSS(Y_full_20[test].squeeze(), Y_pred_20.squeeze() , threshold = 0.5)\n",
        "  CSI_all.append(CSI_index)\n",
        "  POD_all.append(POD_index)\n",
        "  FAR_all.append(FAR_index)\n",
        "  HSS_all.append(HSS_index)\n",
        "  Y_full_20[test] = (Y_full_20[test] - 0.5 * full_20) / (0.5 * full_20)\n",
        "  i = i + 1\n",
        "  "
      ],
      "metadata": {
        "id": "SMrDEkL650vj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SSI_mean = tf.math.reduce_mean(accuracy)\n",
        "print(SSI_mean)\n",
        "# print(tf.math.reduce_mean(accuracy))\n",
        "print(average(CSI_all))\n",
        "print(average(POD_all))\n",
        "print(average(FAR_all))\n",
        "print(average(HSS_all))"
      ],
      "metadata": {
        "id": "av_lCwGeGU_T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
